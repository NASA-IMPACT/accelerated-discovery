from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, START, StateGraph
from langgraph.pregel import RetryPolicy
from pydantic import Field, computed_field

from akd._base import InputSchema, OutputSchema
from akd.agents._base import BaseAgent, BaseAgentConfig
from akd.configs.storm_config import STORM_SETTINGS, StormSettings

from .config import initialise_storm_config
from .nodes import (
    conduct_interviews,
    hitl_editors,
    index_references,
    initialize_research,
    refine_outline,
    write_article,
    write_sections,
)
from .state import ResearchState
from .utils.outline_utils import Perspectives


class StormInputSchema(InputSchema):
    """Input schema for storm agent"""

    config: dict | None = Field(
        None,
        description="The configuration dict to track the state of the storm agent.",
    )

    query: str = Field(
        ...,
        description="The topic to create the article for.",
    )

    @computed_field
    @property
    def topic(self) -> str:
        return self.query


class StormOutputSchema(OutputSchema):
    """Output schema for storm agent"""

    article: str = Field(
        ...,
        description="The article generated by storm.",
    )
    perspectives: Perspectives = Field(
        ...,
        description="List of editors working on the article",
    )
    interview_results: list = Field(
        ...,
        description="Interview results between editors",
    )


class StormAgentConfig(BaseAgentConfig):
    """Configuration for Storm Agent"""

    hitl: bool = Field(
        False,
        description="Whether to set the agent in HITL mode.",
    )

    storm_settings: StormSettings | None = Field(
        default_factory=lambda: STORM_SETTINGS,
        description="The configuration for the storm agent.",
    )


class StormAgent(BaseAgent):
    input_schema = StormInputSchema
    output_schema = StormOutputSchema
    config_schema = StormAgentConfig

    def _post_init(
        self,
    ) -> None:
        super()._post_init()

        storm_settings = self.config.storm_settings or STORM_SETTINGS
        initialise_storm_config(storm_settings)

        storm_builder = StateGraph(ResearchState)

        nodes = [
            ("init_research", initialize_research),
            ("hitl_editors", hitl_editors) if self.hitl else None,
            ("conduct_interviews", conduct_interviews),
            ("refine_outline", refine_outline),
            ("index_references", index_references),
            ("write_sections", write_sections),
            ("write_article", write_article),
        ]
        nodes = [node for node in nodes if node is not None]

        for i in range(len(nodes)):
            name, node = nodes[i]
            storm_builder.add_node(name, node, retry=RetryPolicy(max_attempts=3))
            if i > 0:
                storm_builder.add_edge(nodes[i - 1][0], name)

        storm_builder.add_edge(START, nodes[0][0])
        storm_builder.add_edge(nodes[-1][0], END)
        self.storm = storm_builder.compile(checkpointer=MemorySaver())

    async def get_response_async(
        self,
        params: StormInputSchema,
        **kwargs,
    ) -> StormOutputSchema:
        """
        Obtains a response from the language model asynchronously.

        Args:
            response_model (Optional[OutputSchema]):
                The schema for the response data. If not set,
                self.output_schema is used.

        Returns:
            OutputSchema: The response from the language model.
        """
        config = params.config or {}
        topic = params.topic

        article_state = await self.storm.ainvoke({"topic": topic}, config)
        article = article_state["article"]
        perspectives = article_state["editors"]
        interview_results = article_state["interview_results"]
        return StormOutputSchema(
            article=article,
            perspectives=perspectives,
            interview_results=interview_results,
        )

    async def _arun(self, params: StormInputSchema, **kwargs) -> StormOutputSchema:
        return await self.get_response_async(params, **kwargs)
