OPENAI_API_KEY=sk-proj...
MODEL_CONFIG_SETTINGS__API_KEYS__OPENAI=sk-proj...

# For Storm

# model names for vLLM server / Open AI / Ollama
FAST_LLM=meta-llama/Llama-3.1-8B-Instruct
LONG_CTX_LLM=deepseek-ai/DeepSeek-V3

# server [openai, vllm, ollama]
SERVER=vllm

# base urls for the vLLM / Ollama server
# ollama example: http://127.0.0.1:11434/v1
OPENAI_API_BASE_FAST_LLM="<vllm url for fast llm>"
OPENAI_API_BASE_LONG_CTX_LLM="<vllm url for long context llm>"

# if you're using OpenAI
OPENAI_API_KEY="<openai api key>"

# for IBM, enter your RITS API key here
RITS_API_KEY="<rits api key>"

# placeholder
ADS_API_KEY=

# select one of [duckduckgo, google] (for now)
SEARCH_ENGINE=duckduckgo
# for google
GOOGLE_API_KEY="<google api key>"
GOOGLE_CSE_ID="<google search api key>"

# SearxNG
SEARXNG_BASE_URL="<SEARXNG base url>" #"http://localhost:8080"
SEARXNG_MAX_PAGES=25
SEARXNG_RESULTS_PER_PAGE=10
SEARXNG_SCORE_CUTOFF=0.25
SEARXNG_STRICT=False
SEARXNG_DEBUG=False
SEARXNG_ENGINES="google,arxiv,google_scholar"

# For FactCheck
FACT_CHECK_API_URL="https://factreasoner-service-app.1yhbkn094k2v.us-south.codeengine.appdomain.cloud"
FACT_CHECK_JOB_TIMEOUT="1800"
FACT_CHECK_REQUEST_TIMEOUT="60"
FACT_CHECK_START_ENDPOINT="/fact-check/start"
FACT_CHECK_STATUS_ENDPOINT="/fact-check/status"
FACT_CHECK_CORRECT_ENDPOINT="/correct"
FACT_CHECK_DISPLAY_GRAPH_ENDPOINT="/display_graph"
FACT_CHECK_GRAPH_JSON_ENDPOINT="/graph/json"

# for your vector store
EMBEDDING_MODEL_ID="nasa-impact/nasa-smd-ibm-st-v2"

VECTOR_DB_PATH="./chroma_db"
# API key for various embedding functions (chroma)
EMBEDDING_MODEL_API_KEY=""

# number of wiki results to return
TOP_N_WIKI_RESULTS = 1

# max number of interview turns per interviewee
MAX_NUM_TURNS = 5

# number of times to retry a node
RETRY_ATTEMPTS = 3

# number of editors
NUM_EDITORS = 3
